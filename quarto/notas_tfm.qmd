---
title: Notas TFM
date: today

format:
  html: default

toc: true
toc-title: Content
code-fold: true
wrap: auto
embed-resources: true
warning: false
error: false
---

# Introduction

# Research question
Can we use vector representation of words to detect the difference between inflection and derivation?
  
# Methodology
This study explores the distinction between inflection and derivation in Polish and Spanish using various word embedding models, both static and contextual.

To achieve this, we implemented several models. For static embeddings, we used Word2Vec and FastText, and for contextual embeddings, we utilized the Multilingual BERT model. The Word2Vec model for Spanish was based on the Spanish Billion Words corpus. For Polish, we used the IPIPAN Word2Vec model (nkjp+wiki-forms-all-300-skipg-ns), which is comparable in quality to SBW. It was trained on the National Corpus of Polish (NKJP) and Wikipedia, includes all parts of speech and word forms, and produces 300-dimensional vectors using the skip-gram algorithm with negative sampling.

In addition, we applied FastText embeddings for both Spanish and Polish to incorporate subword-level information. For contextual representation, we used Multilingual BERT (mBERT) to capture context-sensitive nuances in the morphological structures.

In order to conduct an initial analysis we constructed two separate datasets, using data from UniMorph, one for inflection and another one for derivation.

## Initial analysis

### Datasets
For the inflection analysis, we constructed a Pivot/Inflection dataset limited to verb-to-verb (V:V) transformations, since no other category is possible.

* We filtered the data to include the following verb tenses in Spanish:
  * Present Indicative. UniMorph category: V;IND;PRS.
  * Past Imperfect. UniMorph category: V;IND;PST;IPFV
  * Future Indicative. UniMorph category: V;IND;FUT

This resulted in a dataset of 148,051 rows, each consisting of a base form, its inflected variant, and the morphological category. Additional forms such as participles and gerunds are planned for future inclusion.

* In Polish the filtering included:
  * Present. UniMorph category: V;PRS.
  * Past. UniMorph category:V;PST.
  * Future. UniMorph category:V;FUT.

The resulting dataset contains 23,615 rows, structured similarly to the Spanish set with base, inflected form, and category.

For the derivation analysis the data provided by UniMorph was used without changes.

<!-- ejemplito de dataset por aqui -->

### Tables
The initial results are shown in the following tables. 

Mean similarity between pivot and inflection.  

| INFLECTION | WORD2VEC | FASTTEXT | MULTILINGUAL BERT |
| ---------- | -------- | -------- | ----------------- |
| **SPA**    | 0.539277 | 0.555474 | 0.95              |
| **POL**    | 0.513006 | 0.486620 | 0.91              |
|            |          |          | *POLBERT 0.84*    |
|            |          |          | *HERBERT 0.89*    |

Mean similarity between pivot and derivation.

| DERIVATION | WORD2VEC | FASTTEXT | MULTILINGUAL BERT |
| ---------- | -------- | -------- | ----------------- |
| **SPA**    | 0.504810 | 0.511147 | 0.927623          |
| **POL**    | 0.406683 | 0.544072 | 0.931450          |
|            |          |          | *POLBERT 0.89*    |
|            |          |          | *HERBERT 0.92*    |

### Plotting the results of the initial analysis
In this section we plot the initial results. Mean similarity of the category (V:V, ADJ:N, ADV:ADJ...) by type (inflection, derivation between the same categories and derivation between different categories), separated by embeddings model and language.

```{r}
#| echo: false
# set working directory
# print(getwd())
# setwd("C:/PythonCode/TFM_GLS/")
# print(getwd())
```

```{r}
#| echo: false
library(ggplot2)
library(dplyr)

# FASTTEXT
# INFLECTION
spa_ft_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_fasttext_inflection_results.csv")
pol_ft_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_fasttext_inflection_results.csv")
# DERIVATION
spa_ft_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_fasttext_derivation_results.csv")
pol_ft_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_fasttext_derivation_results.csv")

# WORD2VEC
# INFLECTION
spa_w2v_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_word2vec_inflection_results.csv")
pol_w2v_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_word2vec_inflection_results.csv")
# DERIVATION
spa_w2v_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_word2vec_derivation_results.csv")
pol_w2v_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_word2vec_derivation_results.csv")

# BERT
# INFLECTION
spa_bert_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_bert_inflection_results.csv")
pol_bert_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_bert_inflection_results.csv")
# DERIVATION
spa_bert_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_bert_derivation_results.csv")
pol_bert_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_bert_derivation_results.csv")

# adding model, language and type (inf or der) to the dataset in order to plot it
spa_ft_inf <- spa_ft_inf %>%
  mutate(model = "FastText", language = "Spanish", type = "Inflection")

pol_ft_inf <- pol_ft_inf %>%
  mutate(model = "FastText", language = "Polish", type = "Inflection")

spa_ft_der <- spa_ft_der %>%
  mutate(model = "FastText", language = "Spanish", type = "Derivation")

pol_ft_der <- pol_ft_der %>%
  mutate(model = "FastText", language = "Polish", type = "Derivation")

spa_w2v_inf <- spa_w2v_inf %>%
  mutate(model = "Word2Vec", language = "Spanish", type = "Inflection")

pol_w2v_inf <- pol_w2v_inf %>%
  mutate(model = "Word2Vec", language = "Polish", type = "Inflection")

spa_w2v_der <- spa_w2v_der %>%
  mutate(model = "Word2Vec", language = "Spanish", type = "Derivation")

pol_w2v_der <- pol_w2v_der %>%
  mutate(model = "Word2Vec", language = "Polish", type = "Derivation")

spa_bert_inf <- spa_bert_inf %>%
  mutate(model = "Multilingual BERT", language = "Spanish", type = "Inflection")

pol_bert_inf <- pol_bert_inf %>%
  mutate(model = "Multilingual BERT", language = "Polish", type = "Inflection")

spa_bert_der <- spa_bert_der %>%
  mutate(model = "Multilingual BERT", language = "Spanish", type = "Derivation")

pol_bert_der <- pol_bert_der %>%
  mutate(model = "Multilingual BERT", language = "Polish", type = "Derivation")

```

```{r}
#| echo: false

# spa_ft_inf %>% filter(!grepl("Ã¡s", inflection) & grepl("PRS;2;SG", category), 0, ifelse(grepl("FORM", category), 0, 1)))
# spa_ft_der %>% filter (category == "ADJ:ADJ")
# sample

# inflection and derivation datasets
all_inflection <- bind_rows(spa_ft_inf, pol_ft_inf, spa_w2v_inf,
 pol_w2v_inf, spa_bert_inf, pol_bert_inf,)

all_inflection_spa <- bind_rows(spa_ft_inf, spa_w2v_inf, spa_bert_inf)

all_derivation <- bind_rows(spa_ft_der, pol_ft_der, spa_w2v_der,
 pol_w2v_der, spa_bert_der, pol_bert_der)

# # add a new column with "same category" or "different cattegory" to the derivations dataset
all_derivation <- all_derivation %>%
  mutate(type = ifelse(
    gsub(":.*", "", category) == gsub(".*:", "", category),
    "Derivation (same category)", "Derivation (different category)"))

# factoring data (type: inflection, derivation same, derivation diff) on both datasets
all_derivation$type <- as.factor(all_derivation$type)
all_inflection$type <- as.factor(all_inflection$type)
all_inflection_spa$category <- as.factor(all_inflection_spa$category)
# join both datasets
all_df <- bind_rows(all_derivation, all_inflection)

# factor model, language and category
all_df$model <- as.factor(all_df$model)
all_df$language <- as.factor(all_df$language)
all_df$category <- as.factor(all_df$category)

# group by category, model and language and get the mean similarity of each, to plot
# i.e.:       category   model    language   type      mean_similarity
#              ADJ:ADJ   FasText  Polish   Inflection   0.6197
all_df_plot <- all_df %>%
  group_by(category, model, language, type) %>%
  summarise(mean_similarity = mean(similarity, na.rm = TRUE), .groups = 'drop')
```

```{r}
#| column: page
#| echo: false
#| fig-format: svg
#| out-width: 90%
#| fig-width: 22
#| fig-height: 14
#| label: fig-initial-plot
#| fig-cap: "Mean similarity between pivot-form in derivation and inflection by model and language"

# plot1 <- ggplot(all_df_plot, aes(x = type, y = mean_similarity, fill = type)) +
#   geom_dotplot(
#     binaxis = "y", stackdir = "center", 
#     dotsize = 3, binwidth = 0.01, 
#     na.rm = TRUE, alpha = 0.8
#   ) +
#   labs(x = "", y = "Mean similarity") +
#   facet_grid(language ~ model) +
#   stat_summary(
#     fun.data = "mean_cl_boot", 
#     color = "black", size = 1, 
#     position = position_dodge(0.85)
#   ) +
#   theme(
#     plot.margin = margin(t = 10, r = 20, b = 10, l = 40),
#     axis.text.x = element_text(angle = 45, hjust = 1, size = 18),
#     axis.text.y = element_text(size = 16),
#     strip.text = element_text(size = 18)
#   ) +
#   scale_fill_brewer(palette = "Dark2") +
#   guides(fill = "none")
# plot1

# ggsave("C:/PythonCode/TFM_GLS/py/fig-initial-plot.svg", plot = plot1, width = 22, height = 14, units = "in")
```

![Mean similarity between pivot-form in derivation and inflection by model and language](C:/PythonCode/TFM_GLS/py/plots/fig-initial-plot.svg){#fig-initial-plot}


We can see in @fig-initial-plot some weird outliers in FastText and Word2Vec. These outliers correspond to different instances of U:U, X:U or U:X (X being any label). This unknown category is messing with the means so the data needs to be cleaned a bit and we need to keep N, ADJ, ADV and V.

## Cleaning the datasets

### Cleaning derivations

The first analysis revealed some errors in both datasets. In the derivations dataset the label U (that *possibly* means unspecified or unknown) presented some issues. The goal is to eliminate all instances of unknown categories, to get rid of this noise and have cleaner results and means.

1. In Spanish there are 20 rows that contain a derivation that results in U (i.e. N:U or V:U) and 107 in Polish. 
2. On the other hand, there are even more derivations in which the pivot is tagged with U (U:N, U:ADJ...), 36 in Spanish and 253 in Polish. 

Taking a quick look through this data one can see many mistakes such as clear verbs, adjectives or nouns being labeled U and also formatting issues. When it comes to Spanish, the number is not too high, so it is something that is worth fixing in order to get rid of this label so it does not mess with the means shown in @fig-initial-plot. Fixing the first group seems fairly easy since we can just look at the affix and assign the category it gets assigned in other instances. 

```{python}
#| echo: false
#| output: false

import pandas as pd

df = pd.read_csv("C:/PythonCode/TFM_GLS/py/datasets/spa/spa.derivations", sep="\t", header=None, names=["pivot", "derivation", "category", "affix"])

df[df["category"].str.endswith(":U")]
```

In order to clean the Spanish derivations dataset we assign a new category according to the affix. We change all the affixes that end in *-ero*, *-ez*, *-ismo*,*-Ã­* and *-illa* to N. We also assign V to those that contain the affixes *-ar* and *-ear*

```{python}
affixes = ["-ero", "-ez", "-ismo", "-Ã­", "-illa"]
condition = (
  df['category'].str.endswith(':U') & 
  df['affix'].isin(affixes)
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':N', regex=False)

verb_endings = ["-ear", "-ar"]
condition = (
  df['category'].str.endswith(':U') & 
  df['affix'].isin(verb_endings)
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':V', regex=False)

df[df["category"].str.endswith(":U")]
```

As a result we obtain 6 rows that can be eliminated from the final dataset because of all the mistakes they contain.

For the Polish data we do a very similar thing. Affixes such as *-any*, *-ony*, *-ty*, *-y*, or *-Äcy*, *-Äty* take the label ADJ, because they are all endings that participles take. Some of these affixes are wrong, for example *-ty* and *-y*, UniMorph cannot decide if the suffix takes the *-t* or not, but we will ignore this for now.

```{python}
#| echo: false
df = pd.read_csv("C:/PythonCode/TFM_GLS/py/datasets/pol/pol.derivations", sep="\t", header=None, names=["pivot", "derivation", "category", "affix"])
```

```{python}

affixes = ["-any", "-ony", "-ty", "-y", "-Äcy", "-Äty"]
condition = (
  df['category'].str.endswith(':U') & 
  df['affix'].isin(affixes)
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':ADJ', regex=False)
```

We can also see some formatting issues. Some rows contain the pivot and the derived form joined together in the pivot cell (i.e. *myliÄpomyliÄ	pomyliÄ*). This can be fixed as well just removing the form from the pivot column and assigning to them the correct categories. 
```{python}
df["pivot"] = df.apply(lambda row: row['pivot'].replace(row['derivation'], ''), axis=1)
```

We also fixed certain rows that contained verbs in both columns but were not correctly labeled. This is fairly easy since in Polish verbs in the infinitive form end in *-Ä* (most of them) or *-c*. We also labeled three rows incorrectly labeled U:U as ADJ:ADJ since they contained adjectives.

```{python}
condition = (
  df["category"].str.endswith(":U") & 
  df['pivot'].str.endswith("Ä") & 
  df['derivation'].str.endswith('Ä')
)
df.loc[condition, 'category'] = "V:V"

condition = (
  df["category"].str.endswith(":U") & 
  df['pivot'].str.endswith("c") & 
  df['derivation'].str.endswith('c')
)
df.loc[condition, 'category'] = 'V:V'

pivots_to_change = ['zamÄÅ¼ny', 'przystawalny', 'pocieszony']
condition = (
    df["pivot"].isin(pivots_to_change) &
    df["category"].str.endswith(":U")
)
df.loc[condition, 'category'] = 'ADJ:ADJ'

df_u = df[df["category"].str.endswith(":U")]
df_u.sample(15)
```

The rest can be removed as well as they do not contain any nouns, adjectives, adverbs or verbs. Take for instance the appearance of *co*, *kto*, *jaki*.. which are relative pronouns. Everything ending in *-Å* and *-Å¼* or *-Å¼e* are not nouns nor adjectives nor adverbs nor verbs so they can be removed.

The second group of Spanish derivations (:U) cannot be easily fixed with a Python script, it contains many numerals and words that are not N, ADJ, ADV or V. Those rows that do not contain any of such categories can be dropped and the rest probably needs to be fixed manually. It contais some verbs, nouns and adjectives labeled with U, for instance *cuarenta cuanrentÃ³Å U:N -Ã³n*. For some reason *cuarenta* is labeled in other rows as N but not in this one. Since numerals can be N or ADJ, alongside all the other issues with this group I think we can just drop all these rows (35). It is a low number that will not affect the results.

In the Polish dataset we can do better because there are many rows (163) that contain verbs ending in *-Ä* in both the pivot and the derivation column but are incorrectly labeled as U:V, for example *krÄciÄ skrÄcic U:V s-* or *paÅÄ przepaÅÄ U:V prze-*. We can easily change the label to V:V.

```{python}
# Data we cleaned previously
df = pd.read_csv("C:/PythonCode/TFM_GLS/py/datasets/pol/pol_derivations.txt", sep="\t", header=None, names=["pivot", "derivation", "category", "affix"])

condition = (
    df["category"].str.startswith("U:") &
    df['pivot'].str.endswith("Ä") & 
    df['derivation'].str.endswith('Ä')
)

df.loc[condition, 'category'] = 'V:V'
df[condition]
```

There are also 27 rows that contain verbs ending in *-c* in both the pivot and the derivation cells, which can be fixed just like previously done on the other group of verbs.

```{python}
condition = (
    df["category"].str.startswith("U:") &
    df['pivot'].str.endswith("c") & 
    df['derivation'].str.endswith('c')
)

df.loc[condition, 'category'] = 'V:V'
```

Finally we can fix some pivots that are verbs, but are not labeled as such, just by looking at the ending, although this needs to be done carefully as some nouns can also end in *-Ä* or *-c*.

```{python}
condition = (
    df['category'].str.startswith('U:') & 
    df['pivot'].str.endswith('Ä') |
    df['category'].str.startswith('U:') &
    df['pivot'].str.endswith('c')
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace('U:', 'V:', regex=False)
df.loc[condition]
```

Since we have fixed almost 200 rows, the resulting ones labeled as U:X contain only 21 rows, with some mistakes or words that are not N, ADJ, ADV or V so we can just drop them. Both resulting datasets do not contain any more any row labeled with U, so we should get a cleaner mean.

### Cleaning inflections

The only thing to clean in the inflections dataset is