---
title: Notas TFM
date: today

format:
  html: default

toc: true
toc-title: Content
code-fold: true
wrap: auto
embed-resources: true
warning: false
error: false
---

# Introduction

# Research question
Can we use vector representation of words to detect the difference between inflection and derivation?
  
# Methodology
This study explores the distinction between inflection and derivation in Polish and Spanish using various word embedding models, both static and contextual.

To achieve this, we implemented several models. For static embeddings, we used Word2Vec and FastText, and for contextual embeddings, we utilized the Multilingual BERT model. The Word2Vec model for Spanish was based on the Spanish Billion Words corpus. For Polish, we used the IPIPAN Word2Vec model (nkjp+wiki-forms-all-300-skipg-ns), which is comparable in quality to SBW. It was trained on the National Corpus of Polish (NKJP) and Wikipedia, includes all parts of speech and word forms, and produces 300-dimensional vectors using the skip-gram algorithm with negative sampling.

In addition, we applied FastText embeddings for both Spanish and Polish to incorporate subword-level information. For contextual representation, we used Multilingual BERT (mBERT) to capture context-sensitive nuances in the morphological structures.

In order to conduct an initial analysis we constructed two separate datasets, using data from UniMorph, one for inflection and another one for derivation.

## Initial analysis

### Datasets
For the inflection analysis, we constructed a Pivot/Inflection dataset limited to verb-to-verb (V:V) transformations, since no other category is possible.

* We filtered the data to include the following verb tenses in Spanish:
  * Present Indicative. UniMorph category: V;IND;PRS.
  * Past Imperfect. UniMorph category: V;IND;PST;IPFV
  * Future Indicative. UniMorph category: V;IND;FUT

This resulted in a dataset of 148,051 rows, each consisting of a base form, its inflected variant, and the morphological category. Additional forms such as participles and gerunds are planned for future inclusion.

* In Polish the filtering included:
  * Present. UniMorph category: V;PRS.
  * Past. UniMorph category:V;PST.
  * Future. UniMorph category:V;FUT.

The resulting dataset contains 23,615 rows, structured similarly to the Spanish set with base, inflected form, and category.

For the derivation analysis the data provided by UniMorph was used without changes.

<!-- ejemplito de dataset por aqui -->

### Initial results
The initial results are shown in the following tables. 
  
  
::: {#tbl-results-comparison layout-ncol="2"}

| Model             | Language | Initial Analysis |
|-------------------|----------|------------------|
| **FastText**      | Spanish  | 0.555            |
|                   | Polish   | 0.486            |
| **Word2Vec**      | Spanish  | 0.539            |
|                   | Polish   | 0.513            |
| **Mult BERT**     | Spanish  | 0.950            |
|                   | Polish   | 0.910            |

: Mean similarity in inflection {#tbl-initial-inflection} {.sm}


| Model             | Language | Initial Analysis |
|-------------------|----------|------------------|
| **FastText**      | Spanish  | 0.511            |
|                   | Polish   | 0.544            |
| **Word2Vec**      | Spanish  | 0.504            |
|                   | Polish   | 0.406            |
| **Mult BERT**     | Spanish  | 0.927            |
|                   | Polish   | 0.931            |

: Mean similarity in derivation. {#tbl-initial-derivation} {.sm}

Mean similarity in initial results
:::

Now we will plot the initial results. Mean similarity of the category (V:V, ADJ:N, ADV:ADJ...) by type (inflection, derivation between the same categories and derivation between different categories), separated by embeddings model and language.

```{r}
#| echo: false
# set working directory
# print(getwd())
# setwd("C:/PythonCode/TFM_GLS/")
# print(getwd())
```

![Mean similarity between pivot-form in derivation and inflection by model and language](C:/PythonCode/TFM_GLS/py/plots/fig-initial-plot.svg){#fig-initial-plot}

We can see in @fig-initial-plot some weird outliers in FastText and Word2Vec. These outliers correspond to different instances of U:U, X:U or U:X (X being any label). This unknown category is messing with the means so the data needs to be cleaned a bit and we need to keep N, ADJ, ADV and V.

## Cleaning the datasets

### Cleaning derivations

The first analysis revealed some errors in both datasets. In the derivations dataset the label U (that *possibly* means unspecified or unknown) presented some issues. The goal is to eliminate all instances of unknown categories, to get rid of this noise and have cleaner results and means.

1. In Spanish there are 20 rows that contain a derivation that results in U (i.e. N:U or V:U) and 107 in Polish. 
2. On the other hand, there are even more derivations in which the pivot is tagged with U (U:N, U:ADJ...), 36 in Spanish and 253 in Polish. 

Taking a quick look through this data one can see many mistakes such as clear verbs, adjectives or nouns being labeled U and also formatting issues. When it comes to Spanish, the number is not too high, so it is something that is worth fixing in order to get rid of this label so it does not mess with the means shown in @fig-initial-plot. Fixing the first group seems fairly easy since we can just look at the affix and assign the category it gets assigned in other instances.

#### Spanish data

```{python}
#| echo: false
#| output: false

import pandas as pd

df = pd.read_csv("C:/PythonCode/TFM_GLS/py/datasets/spa/spa.derivations", sep="\t", header=None, names=["pivot", "derivation", "category", "affix"])

df[df["category"].str.endswith(":U")]
```

In order to clean the Spanish derivations dataset we assign a new category according to the affix. We change all the affixes that end in *-ero*, *-ez*, *-ismo*,*-í* and *-illa* to N. We also assign V to those that contain the affixes *-ar* and *-ear*

```{python}
affixes = ["-ero", "-ez", "-ismo", "-í", "-illa"]
condition = (
  df['category'].str.endswith(':U') & 
  df['affix'].isin(affixes)
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':N', regex=False)

verb_endings = ["-ear", "-ar"]
condition = (
  df['category'].str.endswith(':U') & 
  df['affix'].isin(verb_endings)
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':V', regex=False)

df[df["category"].str.endswith(":U")]
```

As a result we obtain 6 rows that can be eliminated from the final dataset because of all the mistakes they contain.

The second group of Spanish derivations (:U) cannot be easily fixed with a Python script, it contains many numerals and words that are not N, ADJ, ADV or V. Those rows that do not contain any of such categories can be dropped and the rest probably needs to be fixed manually. It contais some verbs, nouns and adjectives labeled with U, for instance *cuarenta cuanrentóń U:N -ón*. For some reason *cuarenta* is labeled in other rows as N but not in this one. Since numerals can be N or ADJ, alongside all the other issues with this group I think we can just drop all these rows (35). It is a low number that will not affect the results.

#### Polish data
Polish data seems to need more work as there are more incorrect labels, but the positive thing is that it can be fixed more easily. Affixes such as *-any*, *-ony*, *-ty*, *-y*, or *-ący*, *-ęty* take the label ADJ, because they are all endings that participles take.

```{python}
#| echo: false
import pandas as pd
df = pd.read_csv("C:/PythonCode/TFM_GLS/py/datasets/pol/pol.derivations", sep="\t", header=None, names=["pivot", "derivation", "category", "affix"])
```

```{python}
affixes = ["-any", "-ony", "-ty", "-y", "-ący", "-ęty"]
condition = (
  df['category'].str.endswith(':U') & 
  df['affix'].isin(affixes)
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':ADJ', regex=False)
```

We can also see some formatting issues. Some rows under the same condition (X:U) contain the pivot and the derived form joined together in the pivot cell (i.e. *mylićpomylić	pomylić*). This can be fixed as well just removing the form from the pivot column and assigning to row the correct categories. 

```{python}
condition = df['category'].str.endswith(':U')
df.loc[condition, "pivot"] = df.apply(lambda row: row['pivot'].replace(row['derivation'], ''), axis=1)
```

We also fixed certain rows that contained verbs in both columns but were not correctly labeled. This is fairly easy since in Polish verbs in the infinitive form end in *-ć* (most of them) or *-c*. We also labeled three rows incorrectly labeled U:U as ADJ:ADJ since they contained adjectives.

```{python}
condition = (
  df["category"].str.endswith(":U") & 
  df['pivot'].str.endswith("ć") & 
  df['derivation'].str.endswith('ć')
)
df.loc[condition, 'category'] = "V:V"

condition = (
  df["category"].str.endswith(":U") & 
  df['pivot'].str.endswith("c") & 
  df['derivation'].str.endswith('c')
)
df.loc[condition, 'category'] = 'V:V'

pivots_to_change = ['zamężny', 'przystawalny', 'pocieszony']
condition = (
    df["pivot"].isin(pivots_to_change) &
    df["category"].str.endswith(":U")
)
df.loc[condition, 'category'] = 'ADJ:ADJ'

df_u = df[df["category"].str.endswith(":U")]
df_u.sample(15)
```

The table above represents the rest, which can be removed as well as they do not contain any nouns, adjectives, adverbs or verbs. Take for instance the appearance of *co*, *kto*, *jaki*.. which are relative pronouns. Everything ending in *-ś* and *-ż* or *-że* are not nouns nor adjectives nor adverbs nor verbs, but other types of pronouns or particles, so they can be removed.

Regarding the data labeled as U:X, we can do much better than in Spanish because there are many rows (163) that contain verbs ending in *-ć* in both the pivot and the derivation column but are incorrectly labeled as U:V, for example *kręcić skręcic U:V s-* or *paść przepaść U:V prze-*. We can easily change the label to V:V.

```{python}
condition = (
    df["category"].str.startswith("U:") &
    df['pivot'].str.endswith("ć") & 
    df['derivation'].str.endswith('ć')
)

df.loc[condition, 'category'] = 'V:V'
df[condition]
```

There are also 27 rows that contain verbs ending in *-c* in both the pivot and the derivation cells, which can be fixed just like previously done on the other group of verbs.

```{python}
condition = (
    df["category"].str.startswith("U:") &
    df['pivot'].str.endswith("c") & 
    df['derivation'].str.endswith('c')
)

df.loc[condition, 'category'] = 'V:V'
```

Finally we can fix some pivots that are verbs, but are not labeled as such, just by looking at the ending, although this needs to be done carefully as some nouns can also end in *-ć* or *-c*, so we are only doing it on the mislabeled ones (the ones labelled as U), which are all verbs.

```{python}
condition = (
    df['category'].str.startswith('U:') & 
    df['pivot'].str.endswith('ć') |
    df['category'].str.startswith('U:') &
    df['pivot'].str.endswith('c')
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace('U:', 'V:', regex=False)
df.loc[condition]
```

Since we have fixed almost 200 rows, the resulting ones labeled as U:X contain only 21 rows, with some mistakes or words that are not N, ADJ, ADV or V so we can just drop them. Both resulting datasets do not contain any row labeled with U anymore.


### Cleaning inflections

The only thing to clean in the inflections dataset are the *vos* and *usted* forms. This code was added to the filter_unimorph.py script.

```{python}
df = pd.read_csv("C:/PythonCode/TFM_GLS/py/datasets/spa/spa.txt", sep="\t", header=None, names=["pivot", "inflection", "category"])
df = df[
    df["category"].str.contains("V;IND;PRS") | # presente
    df["category"].str.contains("V;IND;PST;IPFV") | # pret. impf.
    df["category"].str.contains("V;IND;FUT") # futuro simple
]

# removing vos forms
df = df[~((df['inflection'].str.endswith('ás') |
     df['inflection'].str.endswith('és') | 
     df['inflection'].str.endswith('ís')) & 
     df['category'].str.contains('V;IND;PRS'))]

# removing usted forms
df = df[~df['category'].str.contains('FORM')]
df.head(10)
```

### Clean data results

```{r}
#| echo: false
#| 
# clean data results
library(ggplot2)
library(dplyr)

# FASTTEXT
# INFLECTION
spa_ft_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_fasttext_inflection_results.csv")
pol_ft_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_fasttext_inflection_results.csv")
# DERIVATION
spa_ft_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_fasttext_derivation_results.csv")
pol_ft_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_fasttext_derivation_results.csv")

# WORD2VEC
# INFLECTION
spa_w2v_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_word2vec_inflection_results.csv")
pol_w2v_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_word2vec_inflection_results.csv")
# DERIVATION
spa_w2v_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_word2vec_derivation_results.csv")
pol_w2v_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_word2vec_derivation_results.csv")

# BERT
# INFLECTION
spa_bert_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_bert_inflection_results.csv")
pol_bert_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_bert_inflection_results.csv")
# DERIVATION
spa_bert_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_bert_derivation_results.csv")
pol_bert_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_bert_derivation_results.csv")
```

```{r}
#| echo: false

# adding model, language and type (inf or der) to the dataset in order to plot it
spa_ft_inf <- spa_ft_inf %>%
  mutate(model = "FastText", language = "Spanish", type = "Inflection")

pol_ft_inf <- pol_ft_inf %>%
  mutate(model = "FastText", language = "Polish", type = "Inflection")

spa_ft_der <- spa_ft_der %>%
  mutate(model = "FastText", language = "Spanish", type = "Derivation")

pol_ft_der <- pol_ft_der %>%
  mutate(model = "FastText", language = "Polish", type = "Derivation")

spa_w2v_inf <- spa_w2v_inf %>%
  mutate(model = "Word2Vec", language = "Spanish", type = "Inflection")

pol_w2v_inf <- pol_w2v_inf %>%
  mutate(model = "Word2Vec", language = "Polish", type = "Inflection")

spa_w2v_der <- spa_w2v_der %>%
  mutate(model = "Word2Vec", language = "Spanish", type = "Derivation")

pol_w2v_der <- pol_w2v_der %>%
  mutate(model = "Word2Vec", language = "Polish", type = "Derivation")

spa_bert_inf <- spa_bert_inf %>%
  mutate(model = "Multilingual BERT", language = "Spanish", type = "Inflection")

pol_bert_inf <- pol_bert_inf %>%
  mutate(model = "Multilingual BERT", language = "Polish", type = "Inflection")

spa_bert_der <- spa_bert_der %>%
  mutate(model = "Multilingual BERT", language = "Spanish", type = "Derivation")

pol_bert_der <- pol_bert_der %>%
  mutate(model = "Multilingual BERT", language = "Polish", type = "Derivation")

```

```{r}
#| echo: false

# spa_ft_inf %>% filter(!grepl("ás", inflection) & grepl("PRS;2;SG", category), 0, ifelse(grepl("FORM", category), 0, 1)))
# spa_ft_der %>% filter (category == "ADJ:ADJ")
# sample

# inflection and derivation datasets
all_inflection <- bind_rows(spa_ft_inf, pol_ft_inf, spa_w2v_inf,
 pol_w2v_inf, spa_bert_inf, pol_bert_inf,)

all_inflection_spa <- bind_rows(spa_ft_inf, spa_w2v_inf, spa_bert_inf)

all_derivation <- bind_rows(spa_ft_der, pol_ft_der, spa_w2v_der,
 pol_w2v_der, spa_bert_der, pol_bert_der)

# # add a new column with "same category" or "different cattegory" to the derivations dataset
all_derivation <- all_derivation %>%
  mutate(type = ifelse(
    gsub(":.*", "", category) == gsub(".*:", "", category),
    "Derivation (same category)", "Derivation (different category)"))

# factoring data (type: inflection, derivation same, derivation diff) on both datasets
all_derivation$type <- as.factor(all_derivation$type)
all_inflection$type <- as.factor(all_inflection$type)
all_inflection_spa$category <- as.factor(all_inflection_spa$category)
# join both datasets
all_df <- bind_rows(all_derivation, all_inflection)

# factor model, language and category
all_df$model <- as.factor(all_df$model)
all_df$language <- as.factor(all_df$language)
all_df$category <- as.factor(all_df$category)

# group by category, model and language and get the mean similarity of each, to plot
# i.e.:       category   model    language   type      mean_similarity
#              ADJ:ADJ   FasText  Polish   Inflection   0.6197
all_df_plot <- all_df %>%
  group_by(category, model, language, type) %>%
  summarise(mean_similarity = mean(similarity, na.rm = TRUE), .groups = 'drop')
```

```{r}
#| column: page
#| echo: false
#| fig-format: svg
#| out-width: 90%
#| fig-width: 22
#| fig-height: 14
#| label: fig-initial-plot
#| fig-cap: "Mean similarity between pivot-form in derivation and inflection by model and language on the cleaned data"

plot1 <- ggplot(all_df_plot, aes(x = type, y = mean_similarity, fill = type)) +
  geom_dotplot(
    binaxis = "y", stackdir = "center", 
    dotsize = 3, binwidth = 0.01, 
    na.rm = TRUE, alpha = 0.8
  ) +
  labs(x = "", y = "Mean similarity") +
  scale_y_continuous(
    limits = c(0, 1),
    breaks = c(0.25, 0.50, 0.75, 1)
  ) +
  stat_summary(
    fun.data = "mean_cl_boot", 
    color = "black", size = 1, 
    position = position_dodge(0.85)
  ) +
  facet_grid(language ~ model) +
  theme(
    plot.margin = margin(t = 10, r = 20, b = 10, l = 40),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 18),
    axis.text.y = element_text(size = 16),
    strip.text = element_text(size = 18)
  ) +
  scale_fill_brewer(palette = "Dark") +
  guides(fill = "none")
  
plot1

# ggsave("C:/PythonCode/TFM_GLS/py/fig-clean-plot.svg", plot = plot1, width = 22, height = 14, units = "in")
```

The lowest category in both FastText and Word2Vec in Polish is V:ADV with a 0.08 and 0.09 mean similarity respectively.

| INFLECTION | WORD2VEC | FASTTEXT | MULTILINGUAL BERT |
| ---------- | -------: | -------: | ----------------: |
| **SPA**    | 0.530683 | 0.550212 |             0.95  |
| **POL**    | 0.513006 | 0.486620 |            0.91   |

: Mean similarity between pivot and inflection on the **clean data** {#tbl-clean-inflection} {.sm}

| DERIVATION | WORD2VEC | FASTTEXT | MULTILINGUAL BERT |
| ---------- | -------: | -------: | ----------------: |
| **SPA**    | 0.504823 | 0.511255 |      0.927637     |
| **POL**    | 0.406783 | 0.544123 |      0.931497     |

: Mean similarity between pivot and derivation on the **clean data** {#tbl-clean-derivation} {.sm}

The change in the means is minimal, less than 0.0001 but I guess we should get a cleaner mean by category in the plot.


## Subset of the most frequent lemmas and affixes (after cleaning)

For this task in Spanish we used the 10000 most frequent lemmas in CREA. We extracted the verbs that appear in both datasets, UniMorph and CREA, and obtained a subset of 1568 lemmas from a total of 6695. 

For the Polish data we used sgjp.pl. We filtered (using the site's implemented filter) the 8500 most common lexemes and took all the verbs from that list which were 1832. After that we compared that list of verbs to the UniMorph data and extracted those that appear in both datasets resulting in 455 lemmas from a total of 844 that appear in the UniMorph data.

To create the subset of affixes, we took the most common affixes in the UniMorph data itself.

::: {#tbl-affixes layout-ncol="2"}

|Affix|Count|
|-----|-----|
|-mente |2997|
|-dor   |1316|
|-ar    |1310|
|-ero   |1123|
|-miento|913|
|-ico   |870|
|des-   |836|
|-ción  |831|
|-ear   |676|
|-ista  |642|
|-ito   |638|
|-ismo  |549|
|-ón    |533|
|-idad  |499|
|-al    |491|

: Spanish {#tbl-spa-affixes} {.sm}

|Affix|Count|
|-----|-----|
|-owy |5804|
|-ka  |5487|
|-anie|3421|
|-ość |3287|
|-ny  |2414|
|-ie  |2161|
|-enie|1669|
|-ek  |1521|
|-ować|1517|
|-o   |1393|
|-ik  |1249|
|-ski |1212|
|-ać  |1158|
|-stwo| 770|
|za-  | 742|

: Polish {#tbl-pol-affixes} {.sm}

Top 15 affixes in Spanish and Polish in UniMorph data.
:::

UniMorph derivation data has 31252 rows in Spanish with 709 unique affixes and 58673 in Polish with 443 unique affixes. After creating a subset dataset of only the top 15 affixes in each language, the result is 14224 rows in Spanish and 33805 in Polish.

### Subset data results

Here is presented a comparison of all the previous analysis and the one done on the subset data. Then a plot in @fig-subset-plot showing the mean similarity of each category on the subset data.

::: {#tbl-results-comparison layout-ncol="2"}

| Model             | Language | Initial Analysis | Clean Data | Subset Data |
|-------------------|----------|--------------------|----------------|-----------------|
| **FastText**      | Spanish  | 0.555              | 0.550          | 0.497           |
|                   | Polish   | 0.486              | 0.486          | 0.490           |
| **Word2Vec**      | Spanish  | 0.539              | 0.530          | 0.504           |
|                   | Polish   | 0.513              | 0.513          | 0.535           |
| **Mult BERT**     | Spanish  | 0.950              | 0.950          | 0.936           |
|                   | Polish   | 0.910              | 0.910          | 0.908           |

: Inflection {#tbl-inflection} {.sm}


| Model             | Language | Initial Analysis | Clean Data | Subset Data |
|-------------------|----------|--------------------|----------------|-----------------|
| **FastText**      | Spanish  | 0.511              | 0.511          | 0.523           |
|                   | Polish   | 0.544              | 0.544          | 0.558           |
| **Word2Vec**      | Spanish  | 0.504              | 0.504          | 0.509           |
|                   | Polish   | 0.406              | 0.406          | 0.401           |
| **Mult BERT**     | Spanish  | 0.927              | 0.927          | 0.931           |
|                   | Polish   | 0.931              | 0.931          | 0.931           |


: Derivation {#tbl-derivation} {.sm}

Mean similarity between pivot and form in inflection and derivation by model and language.
:::

```{r}
#| echo: false
#| 
# subse data results
library(ggplot2)
library(dplyr)

# FASTTEXT
# INFLECTION
spa_ft_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/subset/spa_fasttext_inflection_subset_results.csv")
pol_ft_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/subset/pol_fasttext_inflection_subset_results.csv")
# DERIVATION
spa_ft_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/subset/spa_fasttext_derivation_subset_results.csv")
pol_ft_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/subset/pol_fasttext_derivation_subset_results.csv")

# WORD2VEC
# INFLECTION
spa_w2v_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/subset/spa_word2vec_inflection_subset_results.csv")
pol_w2v_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/subset/pol_word2vec_inflection_subset_results.csv")
# DERIVATION
spa_w2v_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/subset/spa_word2vec_derivation_subset_results.csv")
pol_w2v_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/subset/pol_word2vec_derivation_subset_results.csv")

# BERT
# INFLECTION
spa_bert_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/subset/spa_bert_inflection_subset_results.csv")
pol_bert_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/subset/pol_bert_inflection_subset_results.csv")
# DERIVATION
spa_bert_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/subset/spa_bert_derivation_subset_results.csv")
pol_bert_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/subset/pol_bert_derivation_subset_results.csv")
```

```{r}
#| echo: false

# adding model, language and type (inf or der) to the dataset in order to plot it
spa_ft_inf <- spa_ft_inf %>%
  mutate(model = "FastText", language = "Spanish", type = "Inflection")

pol_ft_inf <- pol_ft_inf %>%
  mutate(model = "FastText", language = "Polish", type = "Inflection")

spa_ft_der <- spa_ft_der %>%
  mutate(model = "FastText", language = "Spanish", type = "Derivation")

pol_ft_der <- pol_ft_der %>%
  mutate(model = "FastText", language = "Polish", type = "Derivation")

spa_w2v_inf <- spa_w2v_inf %>%
  mutate(model = "Word2Vec", language = "Spanish", type = "Inflection")

pol_w2v_inf <- pol_w2v_inf %>%
  mutate(model = "Word2Vec", language = "Polish", type = "Inflection")

spa_w2v_der <- spa_w2v_der %>%
  mutate(model = "Word2Vec", language = "Spanish", type = "Derivation")

pol_w2v_der <- pol_w2v_der %>%
  mutate(model = "Word2Vec", language = "Polish", type = "Derivation")

spa_bert_inf <- spa_bert_inf %>%
  mutate(model = "Multilingual BERT", language = "Spanish", type = "Inflection")

pol_bert_inf <- pol_bert_inf %>%
  mutate(model = "Multilingual BERT", language = "Polish", type = "Inflection")

spa_bert_der <- spa_bert_der %>%
  mutate(model = "Multilingual BERT", language = "Spanish", type = "Derivation")

pol_bert_der <- pol_bert_der %>%
  mutate(model = "Multilingual BERT", language = "Polish", type = "Derivation")

```

```{r}
#| echo: false

# spa_ft_inf %>% filter(!grepl("ás", inflection) & grepl("PRS;2;SG", category), 0, ifelse(grepl("FORM", category), 0, 1)))
# spa_ft_der %>% filter (category == "ADJ:ADJ")
# sample

# inflection and derivation datasets
all_inflection <- bind_rows(spa_ft_inf, pol_ft_inf, spa_w2v_inf,
 pol_w2v_inf, spa_bert_inf, pol_bert_inf,)

all_inflection_spa <- bind_rows(spa_ft_inf, spa_w2v_inf, spa_bert_inf)

all_derivation <- bind_rows(spa_ft_der, pol_ft_der, spa_w2v_der,
 pol_w2v_der, spa_bert_der, pol_bert_der)

# # add a new column with "same category" or "different cattegory" to the derivations dataset
all_derivation <- all_derivation %>%
  mutate(type = ifelse(
    gsub(":.*", "", category) == gsub(".*:", "", category),
    "Derivation (same category)", "Derivation (different category)"))

# factoring data (type: inflection, derivation same, derivation diff) on both datasets
all_derivation$type <- as.factor(all_derivation$type)
all_inflection$type <- as.factor(all_inflection$type)
all_inflection_spa$category <- as.factor(all_inflection_spa$category)
# join both datasets
all_df <- bind_rows(all_derivation, all_inflection)

# factor model, language and category
all_df$model <- as.factor(all_df$model)
all_df$language <- as.factor(all_df$language)
all_df$category <- as.factor(all_df$category)

# group by category, model and language and get the mean similarity of each, to plot
# i.e.:       category   model    language   type      mean_similarity
#              ADJ:ADJ   FasText  Polish   Inflection   0.6197
all_df_plot <- all_df %>%
  group_by(category, model, language, type) %>%
  summarise(mean_similarity = mean(similarity, na.rm = TRUE), .groups = 'drop')

```

```{r}
#| column: page
#| echo: false
#| fig-format: svg
#| out-width: 90%
#| fig-width: 22
#| fig-height: 14
#| label: fig-subset-plot
#| fig-cap: "Mean similarity between pivot-form in derivation and inflection by model and language on the subset data"
#| 
mean_val <- mean(all_df_plot$mean_similarity, na.rm = TRUE)
sd_val <- sd(all_df_plot$mean_similarity, na.rm = TRUE)


plot2 <- ggplot(all_df_plot, aes(x = type, y = mean_similarity, fill = type)) +
  geom_dotplot(
    binaxis = "y", stackdir = "center", 
    dotsize = 3, binwidth = 0.01, 
    na.rm = TRUE, alpha = 0.8
  ) +
  labs(x = "", y = "Mean similarity") +
  scale_y_continuous(
    limits = c(0, 1),
    breaks = c(0.25, 0.50, 0.75, 1)
  ) +
  stat_summary(
    fun.data = "mean_cl_boot", 
    color = "black", size = 1, 
    position = position_dodge(0.85)
  ) +
  facet_grid(language ~ model) +
  theme(
    plot.margin = margin(t = 10, r = 20, b = 10, l = 40),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 18),
    axis.text.y = element_text(size = 16),
    strip.text = element_text(size = 18)
  ) +
  scale_fill_brewer(palette = "Dark") +
  guides(fill = "none")

plot2

# ggsave("C:/PythonCode/TFM_GLS/py/fig-subset-plot.svg", plot = plot1, width = 22, height = 14, units = "in")
```

## Random baseline

We made a random baseline in order to see wheter our methodology holds. For this task we randomly shuffled the data and ran the scripts once again. It consisted in maintaining the order of the pivots and shuffling the rest of the data 10 times in order to obtain a random baseline.

