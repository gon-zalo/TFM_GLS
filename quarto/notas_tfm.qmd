---
title: Notas TFM
date: today

format:
  html: default

toc: true
toc-title: Content
code-fold: true
wrap: auto
embed-resources: true
warning: false
error: false
---

# List of figures
* @fig-initial
* @fig-initial-clean
* @fig-subset
* @fig-random-baseline
* @fig-clean-bert2
* @fig-shuffled-bert2

# Introduction

# Research question
Can we use vector representation of words to detect the difference between inflection and derivation?
  
# Methodology
This study explores the distinction between inflection and derivation in Polish and Spanish using various word embedding models, both static and contextual.

To achieve this, several models were implemented. For static embeddings, used Word2Vec and FastText were used, and for contextual embeddings, the Multilingual BERT model was used. The Word2Vec model for Spanish was trained on the Spanish Billion Words (SBW) corpus. For Polish, the IPIPAN Word2Vec model (nkjp+wiki-forms-all-300-skipg-ns) was used, which is comparable in quality to SBW. It was trained on the National Corpus of Polish (NKJP) and Wikipedia, includes all parts of speech and word forms, and produces 300-dimensional vectors using the skip-gram algorithm with negative sampling. In addition, FastText embeddings for both Spanish and Polish were applied to incorporate subword-level information.

In order to conduct an initial analysis two separate datasets were constructed, using data from UniMorph, one for inflection and another one for derivation.

## Initial analysis

### Datasets
For the inflection analysis, a Pivot/Inflection dataset was constructed.

* The data was filteredto include the following verb tenses in Spanish:
  * Present Indicative. UniMorph category: V;IND;PRS.
  * Past Imperfect. UniMorph category: V;IND;PST;IPFV.
  * Future Indicative. UniMorph category: V;IND;FUT.

This resulted in a dataset of 148,051 rows, each consisting of a base form, its inflected variant, and the morphological category. Additional forms such as participles and gerunds are planned for future inclusion.

* In Polish the filtering included:
  * Present. UniMorph category: V;PRS.
  * Past. UniMorph category:V;PST.
  * Future. UniMorph category:V;FUT.

The resulting dataset contains 23,615 rows, structured similarly to the Spanish set with base, inflected form, and category.

For the derivation analysis the data provided by UniMorph was used without changes.

<!-- ejemplo de dataset por aqui -->

### Initial results
The initial results are shown in the following tables. 
  
  
::: {#tbl-results-initial layout-ncol="2"}

| Model             | Language | Initial Analysis |
|-------------------|----------|------------------|
| **FastText**      | Spanish  | 0.555            |
|                   | Polish   | 0.486            |
| **Word2Vec**      | Spanish  | 0.539            |
|                   | Polish   | 0.513            |
| **Mult BERT**     | Spanish  | 0.950            |
|                   | Polish   | 0.910            |

: Mean similarity in inflection {#tbl-initial-inflection} {.sm}


| Model             | Language | Initial Analysis |
|-------------------|----------|------------------|
| **FastText**      | Spanish  | 0.511            |
|                   | Polish   | 0.544            |
| **Word2Vec**      | Spanish  | 0.504            |
|                   | Polish   | 0.406            |
| **Mult BERT**     | Spanish  | 0.927            |
|                   | Polish   | 0.931            |

: Mean similarity in derivation. {#tbl-initial-derivation} {.sm}

Mean similarity between pivot and form in inflection and derivation by model and language.
:::

The initial results are plotted in the following figure (@fig-initial). Mean similarity of the category (V:V, ADJ:N, ADV:ADJ...) by type (inflection, derivation between the same categories and derivation between different categories), faceted by embeddings model and language.

![Mean similarity between pivot-form in derivation and inflection by model and language](../py/plots/fig-initial.svg){#fig-initial}

In @fig-initial some weird outliers can be seen in FastText and Word2Vec. These outliers correspond to different instances of U:U, X:U or U:X (X being any label). This unknown category is messing with the means so the data needs to be cleaned a bit and N, ADJ, ADV and V need to remain.

```{r}
#| echo: false
knitr::opts_knit$set(root.dir = normalizePath("../py"))

# setwd("C:/PythonCode/TFM_GLS/py")
# getwd()
```

## Cleaning the datasets

### Cleaning derivations

The initial analysis revealed some errors in both datasets. In the derivations dataset the label U (unspecified or unknown) presented some issues. The goal is to eliminate all instances of unknown categories, to get rid of this noise and have cleaner results and means.

1. In Spanish there are 20 rows that contain a derivation that results in U (i.e. N:U or V:U) and 107 in Polish. 
2. On the other hand, there are even more derivations in which the pivot is tagged with U (U:N, U:ADJ...), 36 in Spanish and 253 in Polish. 

Taking a quick look through this data one can see many mistakes such as formatting issues or  verbs, adjectives or nouns being labeled U. When it comes to Spanish, the number is not too high, so it is something that is worth fixing in order to get rid of this label so it does not mess with the means shown in @fig-initial. Fixing the first group seems fairly easy since a category can be assigned based on the affix.

#### Spanish data

```{python}
#| echo: false
#| output: false

import pandas as pd

df = pd.read_csv("datasets/spa/spa.derivations", sep="\t", header=None, names=["pivot", "derivation", "category", "affix"])

df[df["category"].str.endswith(":U")]
```

In order to clean the Spanish derivations dataset a new category according to the affix was assigned. All the affixes that end in *-ero*, *-ez*, *-ismo*,*-í* and *-illa* were changed to N. V was also assigned to those that contain the affixes *-ar* and *-ear*. As a result 6 rows were obtained. They can be eliminated from the final dataset because of all the mistakes they contain.

```{python}
affixes = ["-ero", "-ez", "-ismo", "-í", "-illa"]
condition = (
  df['category'].str.endswith(':U') & 
  df['affix'].isin(affixes)
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':N', regex=False)

verb_endings = ["-ear", "-ar"]
condition = (
  df['category'].str.endswith(':U') & 
  df['affix'].isin(verb_endings)
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':V', regex=False)

df[df["category"].str.endswith(":U")]
```

The second group of Spanish derivations (:U) cannot be easily fixed with a Python script, it contains many numerals and words that are not N, ADJ, ADV or V. Those rows that do not contain any of such categories can be dropped and the rest probably needs to be fixed manually. It contais some verbs, nouns and adjectives labeled with U, for instance *cuarenta cuanrentóń U:N -ón*. For some reason *cuarenta* is labeled in other rows as N but not in this one. Since numerals can be N or ADJ, alongside all the other issues with this group all these rows (35) can be dropped. It is a low number that will not affect the results.

#### Polish data
Polish data seems to need more work as there are more incorrect labels, but it can be fixed more easily. Affixes such as *-any*, *-ony*, *-ty*, *-y*, or *-ący*, *-ęty* take the label ADJ, because they are all endings that participles take.

```{python}
#| echo: false
import pandas as pd
df = pd.read_csv("datasets/pol/pol.derivations", sep="\t", header=None, names=["pivot", "derivation", "category", "affix"])
```

```{python}
affixes = ["-any", "-ony", "-ty", "-y", "-ący", "-ęty"]
condition = (
  df['category'].str.endswith(':U') & 
  df['affix'].isin(affixes)
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':ADJ', regex=False)
```

There also are some formatting issues. Some rows under the same condition (X:U) contain the pivot and the derived form joined together in the pivot cell (i.e. *mylićpomylić	pomylić*). This can be fixed as well just removing the form from the pivot column and assigning to row the correct categories. 

```{python}
condition = df['category'].str.endswith(':U')
df.loc[condition, "pivot"] = df.apply(lambda row: row['pivot'].replace(row['derivation'], ''), axis=1)
```

Some rows that contained verbs in both columns but were not correctly labeled, so they were fixed as well. This was fairly easy since in Polish verbs in the infinitive form end in *-ć* (most of them) or *-c*. Three rows incorrectly labeled U:U were changed to ADJ:ADJ since they contained adjectives.

```{python}
condition = (
  df["category"].str.endswith(":U") & 
  df['pivot'].str.endswith("ć") & 
  df['derivation'].str.endswith('ć')
)
df.loc[condition, 'category'] = "V:V"

condition = (
  df["category"].str.endswith(":U") & 
  df['pivot'].str.endswith("c") & 
  df['derivation'].str.endswith('c')
)
df.loc[condition, 'category'] = 'V:V'

pivots_to_change = ['zamężny', 'przystawalny', 'pocieszony']
condition = (
    df["pivot"].isin(pivots_to_change) &
    df["category"].str.endswith(":U")
)
df.loc[condition, 'category'] = 'ADJ:ADJ'

df_u = df[df["category"].str.endswith(":U")]
df_u.sample(15)
```

The table above represents the rest, which can be removed as well as they do not contain any nouns, adjectives, adverbs or verbs. Take for instance the appearance of *co*, *kto* or *jaki*. which are relative pronouns. Everything ending in *-ś* and *-ż* or *-że* are not nouns nor adjectives nor adverbs nor verbs, but other types of pronouns or particles, so they can be removed.

Regarding the data labeled as U:X, it can be done much better than in Spanish because there are many rows (163) that contain verbs ending in *-ć* in both the pivot and the derivation column but are incorrectly labeled as U:V, for example *kręcić skręcic U:V s-* or *paść przepaść U:V prze-*. The label change to V:V can easily be done. There are also 27 rows that contain verbs ending in *-c* in both the pivot and the derivation cells, which can be fixed just like previously done on the other group of verbs.

```{python}
condition = (
    df["category"].str.startswith("U:") &
    df['pivot'].str.endswith("ć") & 
    df['derivation'].str.endswith('ć')
)

df.loc[condition, 'category'] = 'V:V'

condition = (
    df["category"].str.startswith("U:") &
    df['pivot'].str.endswith("c") & 
    df['derivation'].str.endswith('c')
)

df.loc[condition, 'category'] = 'V:V'
```


Finally some pivots that are verbs but are not labeled as such can be changed just by looking at the ending, although this needs to be done carefully as some nouns can also end in *-ć* or *-c*, for this reason it will only be done on the mislabeled ones (the ones labelled as U), which are all verbs.

```{python}
condition = (
    df['category'].str.startswith('U:') & 
    df['pivot'].str.endswith('ć') |
    df['category'].str.startswith('U:') &
    df['pivot'].str.endswith('c')
)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace('U:', 'V:', regex=False)
```

Since almost 200 rows have been fixed, the resulting ones labeled as U:X contain only 21 rows, with some mistakes or words that are not N, ADJ, ADV or V so they can just be dropped. Both resulting datasets do not contain any row labeled with U anymore.

### Cleaning inflections
The only thing to clean in the inflections dataset are the *vos* and *usted* forms. This code was added to the filter_unimorph.py script.

```{python}
df = pd.read_csv("datasets/spa/spa.txt", sep="\t", header=None, names=["pivot", "inflection", "category"])
df = df[
    df["category"].str.contains("V;IND;PRS") | # presente
    df["category"].str.contains("V;IND;PST;IPFV") | # pret. impf.
    df["category"].str.contains("V;IND;FUT") # futuro simple
]

# removing vos forms
df = df[~((df['inflection'].str.endswith('ás') |
     df['inflection'].str.endswith('és') | 
     df['inflection'].str.endswith('ís')) & 
     df['category'].str.contains('V;IND;PRS'))]

# removing usted forms
df = df[~df['category'].str.contains('FORM')]
df.head(10)
```

### Clean data results
The script main_biplets.py was run again on the clean data.

```{r}
#| echo: false
#| 
# clean data results
library(ggplot2)
library(dplyr)
library(readr)

# FASTTEXT
# INFLECTION
spa_ft_inf <- read.csv("results/spa/spa_fasttext_inflection_results.csv")
pol_ft_inf <- read.csv("results/pol/pol_fasttext_inflection_results.csv")
# DERIVATION
spa_ft_der <- read.csv("results/spa/spa_fasttext_derivation_results.csv")
pol_ft_der <- read.csv("results/pol/pol_fasttext_derivation_results.csv")

# WORD2VEC
# INFLECTION
spa_w2v_inf <- read.csv("results/spa/spa_word2vec_inflection_results.csv")
pol_w2v_inf <- read.csv("results/pol/pol_word2vec_inflection_results.csv")
# DERIVATION
spa_w2v_der <- read.csv("results/spa/spa_word2vec_derivation_results.csv")
pol_w2v_der <- read.csv("results/pol/pol_word2vec_derivation_results.csv")

# BERT
# INFLECTION
spa_bert_inf <- read.csv("results/spa/spa_bert_inflection_results.csv")
pol_bert_inf <- read.csv("results/pol/pol_bert_inflection_results.csv")
# DERIVATION
spa_bert_der <- read.csv("results/spa/spa_bert_derivation_results.csv")
pol_bert_der <- read.csv("results/pol/pol_bert_derivation_results.csv")
```

```{r}
#| echo: false

# spa_ft_inf %>% filter(!grepl("ás", inflection) & grepl("PRS;2;SG", category), 0, ifelse(grepl("FORM", category), 0, 1)))
# spa_ft_der %>% filter (category == "ADJ:ADJ")
# sample

### FUNCTIONS ###
# function to annotate dataset
annotate_dataset <- function(data, model, language, type, version) {
  data %>%
    mutate(model = model, language = language, type = type, version = version)
}

# function to separate same category from different cateogry in derivation
categorize_derivation <- function(data) {
  data %>%
    mutate(type = ifelse(
      gsub(":.*", "", category) == gsub(".*:", "", category),
      "Derivation (same category)",
      "Derivation (different category)"
    )) %>%
    mutate(type = as.factor(type))
}

# function to factor data
prepare_dataset <- function(data) {
  data %>%
    filter(model == "FastText" | model == "Word2Vec") %>% 
    mutate(
      model = as.factor(model),
      language = as.factor(language),
      category = as.factor(category),
      type = as.factor(type),
      version = as.factor(version)
    )
}

# function to group by category, model and language and get the mean similarity of each, to plot
# i.e.:       category   model    language   type      mean_similarity
#              ADJ:ADJ   FasText  Polish   Inflection   0.6197
compute_mean <- function(data) {
  data %>%
    group_by(category, model, language, type, version) %>%
    summarise(mean_similarity = mean(similarity, na.rm = TRUE), .groups = "drop")
}

# plotting function
plot_similarity <- function(data) {
  ggplot(data, aes(x = type, y = mean_similarity, fill = type)) +
    geom_dotplot(
      binaxis = "y", stackdir = "center", 
      dotsize = 2.75, binwidth = 0.01, 
      na.rm = TRUE, alpha = 0.8
    ) +
    labs(x = "", y = "Mean similarity") +
    scale_y_continuous(
      limits = c(0, 1),
      breaks = c(0, 0.25, 0.50, 0.75, 1)
    ) +
    stat_summary(
      fun.data = "mean_cl_boot", 
      color = "black", size = 0.4, alpha = 0.75,
      position = position_dodge(0.85)
    ) +
    facet_grid(language ~ model) +
    theme_minimal() +
    theme(
      axis.title.y = element_text(size = 14),
      plot.margin = margin(t = 10, r = 20, b = 10, l = 40),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
      axis.text.y = element_text(size = 14),
      strip.text = element_text(size = 14, face= "bold"),
    ) +
    scale_fill_manual(values = c(
      "Derivation (same category)" = "#FFE45E",
      "Derivation (different category)" = "#ff7f0e",
      "Inflection" = "#2D93AD"
    )) +
    guides(fill = "none")
}
```

```{r}
#| echo: false

# adding model, language and type (inf or der) to the dataset in order to plot it
spa_ft_inf <- annotate_dataset(spa_ft_inf, 'FastText', 'Spanish', 'Inflection', 'Clean')
pol_ft_inf <- annotate_dataset(pol_ft_inf, 'FastText', 'Polish', 'Inflection', 'Clean')
spa_ft_der <- annotate_dataset(spa_ft_der, 'FastText', 'Spanish', 'Derivation', 'Clean')
pol_ft_der <- annotate_dataset(pol_ft_der, 'FastText', 'Polish', 'Derivation', 'Clean')

spa_w2v_inf <- annotate_dataset(spa_w2v_inf, 'Word2Vec', 'Spanish', 'Inflection', 'Clean')
pol_w2v_inf <- annotate_dataset(pol_w2v_inf, 'Word2Vec', 'Polish', 'Inflection', 'Clean')
spa_w2v_der <- annotate_dataset(spa_w2v_der, 'Word2Vec', 'Spanish', 'Derivation', 'Clean')
pol_w2v_der <- annotate_dataset(pol_w2v_der, 'Word2Vec', 'Polish', 'Derivation', 'Clean')

spa_bert_inf <- annotate_dataset(spa_bert_inf, 'Multilingual BERT', 'Spanish', 'Inflection', 'Clean')
pol_bert_inf <- annotate_dataset(pol_bert_inf, 'Multilingual BERT', 'Polish', 'Inflection', 'Clean')
spa_bert_der <- annotate_dataset(spa_bert_der, 'Multilingual BERT', 'Spanish', 'Derivation', 'Clean')
pol_bert_der <- annotate_dataset(pol_bert_der, 'Multilingual BERT', 'Polish', 'Derivation', 'Clean')

# inflection and derivation datasets
all_inflection <- bind_rows(spa_ft_inf, pol_ft_inf, spa_w2v_inf,
 pol_w2v_inf, spa_bert_inf, pol_bert_inf,)

all_derivation <- bind_rows(spa_ft_der, pol_ft_der, spa_w2v_der,
 pol_w2v_der, spa_bert_der, pol_bert_der)

all_derivation <- categorize_derivation(all_derivation)

all_derivation <- prepare_dataset(all_derivation)
all_inflection <- prepare_dataset(all_inflection)

# join both datasets
all_df <- bind_rows(all_derivation, all_inflection)

all_df <- prepare_dataset(all_df)

all_df_plot <- compute_mean(all_df)

# write.csv(all_df_plot, "results/clean_data_v1.csv", row.names=FALSE)
```

```{r}
#| column: page
#| echo: false
#| fig-format: svg
#| out-width: 100%
#| fig-width: 12
#| fig-height: 10
#| label: fig-initial-clean
#| fig-cap: "Mean similarity between pivot-form in derivation and inflection by model and language on the clean data"

clean_data_v1 <- read.csv("results/baseline/clean_data_v1.csv")

clean_data_v1 <- prepare_dataset(clean_data_v1)

clean_data_v1$model <- factor(clean_data_v1$model, levels = c("FastText", "Word2Vec", "Multilingual BERT"))

plot1 <- plot_similarity(clean_data_v1)

plot1

# ggsave("plots/fig-initial-clean.pdf", plot = plot1, width = 10, height = 8, units = "in")
```

The lowest category in both FastText and Word2Vec in Polish is V:ADV with a 0.08 and 0.09 mean similarity respectively.

::: {#tbl-results-clean layout-ncol="2"}

| Model             | Language | Mean Similarity |
|-------------------|----------|-----------------|
| **FastText**      | Spanish  | 0.55|
|                   | Polish   | 0.48|
| **Word2Vec**      | Spanish  | 0.53|
|                   | Polish   | 0.51|
| **Mult BERT**     | Spanish  | 0.95|
|                   | Polish   | 0.91|

: Inflection {#tbl-inflection} {.sm}


| Model             | Language | Mean Similarity |
|-------------------|----------|-----------------|
| **FastText**      | Spanish  | 0.51|
|                   | Polish   | 0.54|
| **Word2Vec**      | Spanish  | 0.50|
|                   | Polish   | 0.40|
| **Mult BERT**     | Spanish  | 0.92|
|                   | Polish   | 0.93|


: Derivation {#tbl-derivation} {.sm}

Mean similarity between pivot and form in inflection and derivation by model and language on the clean data.
:::


After cleaning the data the change in the means is minimal, less than 0.0001 (and some do not change).

## Subset of the most frequent lemmas and affixes

For this task in Spanish the 10000 most frequent lemmas in CREA was used. The verbs that appear in both datasets, UniMorph and CREA, were extracted and a subset of 1568 lemmas was obtained from a total of 6695. 

For the Polish data sgjp.pl was used. Using the site's implemented filter the 8500 most common lexemes were extracted and after filtering the verbs from that list, 1832 verbs were obtained. Afterwards that list of verbs was compared to the UniMorph data and  those that appear in both datasets were extracted resulting in 455 lemmas from a total of 844 that appear in the UniMorph data.

To create the subset of affixes, the most common affixes in the UniMorph data itself were taken.

::: {#tbl-affixes layout-ncol="2"}

|Affix|Count|
|-----|-----|
|-mente |2997|
|-dor   |1316|
|-ar    |1310|
|-ero   |1123|
|-miento|913|
|-ico   |870|
|des-   |836|
|-ción  |831|
|-ear   |676|
|-ista  |642|
|-ito   |638|
|-ismo  |549|
|-ón    |533|
|-idad  |499|
|-al    |491|

: Spanish {#tbl-spa-affixes} {.sm}

|Affix|Count|
|-----|-----|
|-owy |5804|
|-ka  |5487|
|-anie|3421|
|-ość |3287|
|-ny  |2414|
|-ie  |2161|
|-enie|1669|
|-ek  |1521|
|-ować|1517|
|-o   |1393|
|-ik  |1249|
|-ski |1212|
|-ać  |1158|
|-stwo| 770|
|za-  | 742|

: Polish {#tbl-pol-affixes} {.sm}

Top 15 affixes in Spanish and Polish in UniMorph data.
:::

UniMorph derivation data has 31252 rows in Spanish with 709 unique affixes and 58673 in Polish with 443 unique affixes. After creating a subset dataset of only the top 15 affixes (there is no rationale behind this number) in each language, the result is 14224 rows in Spanish and 33805 in Polish.

### Subset data results

The script was run again on the subset data and the results are presented here.

::: {#tbl-results-subset layout-ncol="2"}

| Model             | Language | Subset Data |
|-------------------|----------|-------------|
| **FastText**      | Spanish  | 0.49|
|                   | Polish   | 0.49|
| **Word2Vec**      | Spanish  | 0.50|
|                   | Polish   | 0.53|
| **Mult BERT**     | Spanish  | 0.93|
|                   | Polish   | 0.90|

: Inflection {#tbl-inflection} {.sm}


| Model             | Language | Subset Data |
|-------------------|----------|-------------|
| **FastText**      | Spanish  | 0.52|
|                   | Polish   | 0.55|
| **Word2Vec**      | Spanish  | 0.50|
|                   | Polish   | 0.40|
| **Mult BERT**     | Spanish  | 0.93|
|                   | Polish   | 0.93|


: Derivation {#tbl-derivation} {.sm}

Mean similarity between pivot and form in inflection and derivation by model and language on the **subset** data.
:::

```{r}
#| column: page
#| echo: false
#| fig-format: svg
#| out-width: 100%
#| fig-width: 12
#| fig-height: 10
#| label: fig-subset
#| fig-cap: "Mean similarity between pivot-form in derivation and inflection by model and language on the subset data"


# mean_val <- mean(all_df_plot$mean_similarity, na.rm = TRUE)
# sd_val <- sd(all_df_plot$mean_similarity, na.rm = TRUE)

subset_data_v1 <- read.csv("results/baseline/subset_data_v1.csv")

subset_data_v1 <- prepare_dataset(subset_data_v1)

subset_data_v1$model <- factor(subset_data_v1$model, levels = c("FastText", "Word2Vec", "Multilingual BERT"))

plot2 <- plot_similarity(subset_data_v1)

plot2

# ggsave("plots/fig-subset-plot.pdf", plot = plot2, width = 10, height = 8, units = "in")
```


#### Comparing all the results
Here is presented a comparison of all the previous analysis and the one done on the subset data. Then a plot in @fig-subset showing the mean similarity of each category on the subset data.

::: {#tbl-results-all layout-ncol="2"}

| Model             | Language | Initial Analysis | Clean Data | Subset Data |
|-------------------|----------|--------------------|----------------|--------|
| **FastText**      | Spanish  | 0.55              | 0.55          | 0.49           |
|                   | Polish   | 0.48              | 0.48          | 0.49           |
| **Word2Vec**      | Spanish  | 0.53              | 0.53          | 0.50           |
|                   | Polish   | 0.51              | 0.51          | 0.53           |
| **Mult BERT**     | Spanish  | 0.95              | 0.95          | 0.93           |
|                   | Polish   | 0.91              | 0.91          | 0.90           |

: Inflection {#tbl-inflection} {.sm}


| Model             | Language | Initial Analysis | Clean Data | Subset Data |
|-------------------|----------|--------------------|----------------|-----------------|
| **FastText**      | Spanish  | 0.51              | 0.51          | 0.52           |
|                   | Polish   | 0.54              | 0.54          | 0.55           |
| **Word2Vec**      | Spanish  | 0.50              | 0.50          | 0.50           |
|                   | Polish   | 0.40              | 0.40          | 0.40           |
| **Mult BERT**     | Spanish  | 0.92              | 0.92          | 0.93           |
|                   | Polish   | 0.93              | 0.93          | 0.93           |


: Derivation {#tbl-derivation} {.sm}

Mean similarity between pivot and form in inflection and derivation by model, language and data.
:::

## Random baseline/Shuffled data

In order to properly evaluate the performance a random baseline was implemented. For this, the data was randomly shuffled 10 times and the scripts were ran once again.

```{python}
#| fig-cap: "Sample of 10 random rows from one shuffled dataset"
import pandas as pd
df = pd.read_csv("datasets/spa/spa_derivations_shuffled.txt", sep="\t", header=None, names=["pivot", "derivation", "category", "affix"])

df.sample(10, random_state=123)
```



```{r}
#| column: page
#| echo: false
#| fig-format: svg
#| out-width: 100%
#| fig-width: 12
#| fig-height: 10
#| label: fig-random-baseline
#| fig-cap: "Mean similarity on the shuffled data."

random_baseline <- read.csv("results/baseline/random_baseline_v1.csv")

random_baseline <- prepare_dataset(random_baseline)

random_baseline$model <- factor(random_baseline$model, levels = c("FastText", "Word2Vec", "Multilingual BERT"))

plot3 <- plot_similarity(random_baseline)

plot3

# ggsave("plots/fig-random-baseline.pdf", plot = plot3, width = 10, height = 8, units = "in")
```


## Implementing RoBERTa and PolBERT

One thing is apparent right away, the results using Multilingual BERT do not make sense. The problem might be that this particular BERT model is trained on many languages and they are interfering with the task. To test this I tested two other BERT based models, one for Polish (PolBERT) and one for Spanish (RoBERTa), the results should be better since these models have only access to a single language.


| Model             | Type | Clean Data | Subset Data | Shuffled Data |
|-------------------|----------|--------------------|----------------|-----------------|
| **RoBERTa**       | Inflection | 0.84             | 0.82          | 0.67           |
|                   | Derivation | 0.81             | 0.82          | 0.65           |
| **PolBERT**       | Inflection | 0.77             | 0.73          | 0.59           |
|                   | Derivation | 0.81             | 0.83          | 0.58           |

The results might still not be the best but at least the mean similarity is lower in the shuffled data than in the clean data.

The following shows the results of the same scripts, this time using RoBERTa and PolBERT instead of Multilingual BERT.

### Clean data results using RoBERTa and PolBERT

```{r}
#| column: page
#| echo: false
#| fig-format: svg
#| out-width: 100%
#| fig-width: 12
#| fig-height: 10
#| label: fig-clean-bert2
#| fig-cap: "Mean similarity on the clean data using RoBERTa and PolBERT."

clean_data <- read.csv("results/clean_data.csv")

clean_data <- prepare_dataset(clean_data)

clean_data$model <- factor(clean_data$model, levels = c("FastText", "Word2Vec", "BERT"))

plot4 <- plot_similarity(clean_data)

plot4

# ggsave("plots/fig-clean.pdf", plot = plot4, width = 10, height = 8, units = "in")
```



### Shuffled data results using RoBERTa and PolBERT


```{r}
#| column: page
#| echo: false
#| fig-format: svg
#| out-width: 100%
#| fig-width: 12
#| fig-height: 10
#| label: fig-shuffled-bert2
#| fig-cap: "Mean similarity using RoBERTa and PolBERT on the shuffled data."

random_baseline_v2 <- read.csv("results/baseline/random_baseline_v2.csv")

random_baseline_v2 <- prepare_dataset(random_baseline_v2)

random_baseline_v2$model <- factor(random_baseline_v2$model, levels = c("FastText", "Word2Vec", "BERT"))

plot5 <- plot_similarity(random_baseline_v2)

plot5

# ggsave("plots/fig-shuffled-bert2.pdf", plot = plot5, width = 10, height = 8, units = "in")
```



### Subset data results using RoBERTa and PolBERT

```{r}
#| echo: false

# FASTTEXT
# INFLECTION
spa_ft_inf <- read.csv("results/spa/subset/spa_fasttext_inflection_subset_results.csv")
pol_ft_inf <- read.csv("results/pol/subset/pol_fasttext_inflection_subset_results.csv")
# DERIVATION
spa_ft_der <- read.csv("results/spa/subset/spa_fasttext_derivation_subset_results.csv")
pol_ft_der <- read.csv("results/pol/subset/pol_fasttext_derivation_subset_results.csv")

# WORD2VEC
# INFLECTION
spa_w2v_inf <- read.csv("results/spa/subset/spa_word2vec_inflection_subset_results.csv")
pol_w2v_inf <- read.csv("results/pol/subset/pol_word2vec_inflection_subset_results.csv")
# DERIVATION
spa_w2v_der <- read.csv("results/spa/subset/spa_word2vec_derivation_subset_results.csv")
pol_w2v_der <- read.csv("results/pol/subset/pol_word2vec_derivation_subset_results.csv")

# BERT
# INFLECTION
spa_bert_inf <- read.csv("results/spa/subset/spa_roberta_inflection_subset_results.csv")
pol_bert_inf <- read.csv("results/pol/subset/pol_polbert_inflection_subset_results.csv")
# DERIVATION
spa_bert_der <- read.csv("results/spa/subset/spa_roberta_derivation_subset_results.csv")
pol_bert_der <- read.csv("results/pol/subset/pol_polbert_derivation_subset_results.csv")
```

```{r}
#| echo: false

# adding model, language and type (inf or der) to the dataset in order to plot it
spa_ft_inf <- annotate_dataset(spa_ft_inf, 'FastText', 'Spanish', 'Inflection', 'Subset')
pol_ft_inf <- annotate_dataset(pol_ft_inf, 'FastText', 'Polish', 'Inflection', 'Subset')
spa_ft_der <- annotate_dataset(spa_ft_der, 'FastText', 'Spanish', 'Derivation', 'Subset')
pol_ft_der <- annotate_dataset(pol_ft_der, 'FastText', 'Polish', 'Derivation', 'Subset')

spa_w2v_inf <- annotate_dataset(spa_w2v_inf, 'Word2Vec', 'Spanish', 'Inflection', 'Subset')
pol_w2v_inf <- annotate_dataset(pol_w2v_inf, 'Word2Vec', 'Polish', 'Inflection', 'Subset')
spa_w2v_der <- annotate_dataset(spa_w2v_der, 'Word2Vec', 'Spanish', 'Derivation', 'Subset')
pol_w2v_der <- annotate_dataset(pol_w2v_der, 'Word2Vec', 'Polish', 'Derivation', 'Subset')

spa_bert_inf <- annotate_dataset(spa_bert_inf, 'BERT', 'Spanish', 'Inflection', 'Subset')
pol_bert_inf <- annotate_dataset(pol_bert_inf, 'BERT', 'Polish', 'Inflection', 'Subset')
spa_bert_der <- annotate_dataset(spa_bert_der, 'BERT', 'Spanish', 'Derivation', 'Subset')
pol_bert_der <- annotate_dataset(pol_bert_der, 'BERT', 'Polish', 'Derivation', 'Subset')

# inflection and derivation datasets
all_inflection <- bind_rows(spa_ft_inf, pol_ft_inf, spa_w2v_inf,
 pol_w2v_inf, spa_bert_inf, pol_bert_inf,)

all_derivation <- bind_rows(spa_ft_der, pol_ft_der, spa_w2v_der,
 pol_w2v_der, spa_bert_der, pol_bert_der)

all_derivation <- categorize_derivation(all_derivation)

all_derivation <- prepare_dataset(all_derivation)
all_inflection <- prepare_dataset(all_inflection)

# join both datasets
all_df <- bind_rows(all_derivation, all_inflection)

all_df <- prepare_dataset(all_df)

all_df_plot <- compute_mean(all_df)

# write.csv(all_df_plot, "results/subset_data.csv", row.names=FALSE)
```


```{r}
#| column: page
#| echo: false
#| fig-format: svg
#| out-width: 100%
#| fig-width: 12
#| fig-height: 10
#| label: fig-subset-v2
#| fig-cap: "Mean similarity on the subset data using RoBERTa and PolBERT"

subset_data <- read.csv("results/subset_data.csv")

subset_data <- prepare_dataset(subset_data)

subset_data$model <- factor(subset_data$model, levels = c("FastText", "Word2Vec", "BERT"))

plot6 <- plot_similarity(subset_data)

plot6

# ggsave("plots/fig-subset.pdf", plot = plot6, width = 10, height = 8, units = "in")
```

## Baseline. Shuffling by category/tense

The previous baseline shuffled the whole data 10 times. In this case a better baseline is implemented. It consists of filtering the data, that is separately filtering inflections by tense (present, past or future) and derivations by category, then shuffling each filter 100 times while extracting the mean similarity of the whole filtered data. That means we are extracting the mean similarity a hundred times by type of morphological process (inflection or derivation), tense/category, model and language and plotting its distribution.

```{r}
#| echo: false

# function to group by category, model and language and get the mean similarity of each, to plot
# i.e.:       category   model    language   type      mean_similarity
#              ADJ:ADJ   FasText  Polish   Inflection   0.6197
# compute_mean <- function(data) {
#   data %>%
#     group_by(category, model, language, type, version) %>%
#     summarise(mean_similarity = mean(similarity, na.rm = TRUE), .groups = "drop")
# }

baseline_data <- read.csv("results/random_baseline.csv")

baseline_data <- baseline_data %>% 
  filter(category != "ADV:V")

baseline_data <- prepare_dataset(baseline_data)

clean_data <- read.csv("results/clean_data.csv")
clean_data <- prepare_dataset(clean_data)
clean_data$model <- factor(clean_data$model, levels = c("FastText", "Word2Vec", "BERT"))

overall_mean_data <- clean_data %>%
  filter(model == "FastText" | model == "Word2Vec") %>% # remove this when bert data is obtained
  group_by(model, language, type) %>% 
  summarise(overall_mean = mean(mean_similarity, na.rm = TRUE), .groups = "drop")

```

```{r}
#| column: page
#| echo: false
#| fig-format: svg
#| out-width: 100%
#| fig-width: 8
#| fig-height: 14
#| label: fig-baseline-faceted
#| fig-cap: "Baseline faceted by model, language and type"

plot8 <- ggplot(baseline_data, aes(x = mean_similarity, fill = type)) +
  geom_histogram(binwidth = 0.01, alpha = 0.7, position = "identity", color = 'black') +
  labs(x = "Mean similarity", y = "Count", fill = "Type") +
  facet_grid(type ~ language ~ model) +
  geom_vline(data = overall_mean_data, aes(xintercept = overall_mean, linetype = "Threshold"), color = "black", size = 0.5) +
  scale_linetype_manual(name = "Mean similarity on the clean data", values = c("Threshold" = "dotted")) +
  theme_minimal() +
  theme(
    # axis.title.y = element_text(size = 30),
    # legend.position = "none",
    plot.margin = margin(t = 10, r = 0, b = 10, l = 160),
    axis.text.x = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.text.y = element_text(size = 10),
    axis.title.y = element_text(size = 11),
    # legend.title = element_text(size = 16),
    # legend.text = element_text(size = 14),
    strip.text = element_text(size = 10, face = "bold")
  ) +
  scale_fill_manual(values = c(
      "Derivation (same category)" = "#FFE45E",
      "Derivation (different category)" = "#ff7f0e",
      "Inflection" = "#2D93AD"
    ))
  
plot8

# ggsave("plots/fig-baseline-faceted.pdf", plot = plot8, width = 12, height = 10, units = "in")
```

```{python}
# import pandas as pd
# import glob
# import os

# # Path to the folder containing your CSVs
# folder_path = "results/baseline"

# # Get all CSV file paths
# csv_files = glob.glob(os.path.join(folder_path, "*.csv"))

# # Read and merge all CSVs into a single DataFrame
# df_list = [pd.read_csv(file) for file in csv_files]
# merged_df = pd.concat(df_list, ignore_index=True)

# merged_df.to_csv("results/baseline/random_baseline.csv", sep=",", index=False)

```

```{r}

# baseline2 <- read.csv("results/random_baseline2.csv")

# baseline2 <- annotate_dataset(baseline2, version = "Shuffled")

# baseline2 <- mutate(baseline2, type = ifelse(
#     type != "Inflection",
#     ifelse(
#       gsub(":.*", "", category) == gsub(".*:", "", category),
#       "Derivation (same category)",
#       "Derivation (different category)"
#     ),
#     type  # leave "Inflection" as is
#   ))

# baseline2 <- prepare_dataset(baseline2)

# summary(baseline2)

# write.csv(baseline2, "results/random_baseline3.csv", row.names = FALSE)
```