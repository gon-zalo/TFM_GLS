---
title: Notas TFM
date: today

format:
  html: default

toc: true
toc-title: Content
code-fold: true
wrap: auto
embed-resources: true
warning: false
error: false
---

# Introduction

# Research question
Can we use vector representation of words to detect the difference between inflection and derivation?
  
# Methodology
This study explores the distinction between inflection and derivation in Polish and Spanish using various word embedding models, both static and contextual.

To achieve this, we implemented several models. For static embeddings, we used Word2Vec and FastText, and for contextual embeddings, we utilized the Multilingual BERT model. The Word2Vec model for Spanish was based on the Spanish Billion Words corpus. For Polish, we used the IPIPAN Word2Vec model (nkjp+wiki-forms-all-300-skipg-ns), which is comparable in quality to SBW. It was trained on the National Corpus of Polish (NKJP) and Wikipedia, includes all parts of speech and word forms, and produces 300-dimensional vectors using the skip-gram algorithm with negative sampling.

In addition, we applied FastText embeddings for both Spanish and Polish to incorporate subword-level information. For contextual representation, we used Multilingual BERT (mBERT) to capture context-sensitive nuances in the morphological structures.

In order to conduct an initial analysis we constructed two separate datasets, using data from UniMorph, one for inflection and another one for derivation.

## Initial analysis

### Datasets
For the inflection analysis, we constructed a Pivot/Inflection dataset limited to verb-to-verb (V:V) transformations, since no other category is possible.

* We filtered the data to include the following verb tenses in Spanish:
  * Present Indicative. UniMorph category: V;IND;PRS.
  * Past Imperfect. UniMorph category: V;IND;PST;IPFV
  * Future Indicative. UniMorph category: V;IND;FUT

This resulted in a dataset of 148,051 rows, each consisting of a base form, its inflected variant, and the morphological category. Additional forms such as participles and gerunds are planned for future inclusion.

* In Polish the filtering included:
  * Present. UniMorph category: V;PRS.
  * Past. UniMorph category:V;PST.
  * Future. UniMorph category:V;FUT.

The resulting dataset contains 23,615 rows, structured similarly to the Spanish set with base, inflected form, and category.

For the derivation analysis the data provided by UniMorph was used without changes.

<!-- ejemplito de dataset por aqui -->

### Tables
The initial results are shown in the following tables. 

Mean similarity between pivot and inflection.  

| INFLECTION | WORD2VEC | FASTTEXT | MULTILINGUAL BERT |
| ---------- | -------- | -------- | ----------------- |
| **SPA**    | 0.539277 | 0.555474 | 0.95              |
| **POL**    | 0.513006 | 0.486620 | 0.91              |
|            |          |          | *POLBERT 0.84*    |
|            |          |          | *HERBERT 0.89*    |

Mean similarity between pivot and derivation.

| DERIVATION | WORD2VEC | FASTTEXT | MULTILINGUAL BERT |
| ---------- | -------- | -------- | ----------------- |
| **SPA**    | 0.504810 | 0.511147 | 0.927623          |
| **POL**    | 0.406683 | 0.544072 | 0.931450          |
|            |          |          | *POLBERT 0.89*    |
|            |          |          | *HERBERT 0.92*    |

### Plotting the results of the initial analysis
In this section we plot the initial results. Mean similarity of the category (V:V, ADJ:N, ADV:ADJ...) by type (inflection, derivation between the same categories and derivation between different categories), separated by embeddings model and language.

```{r}
#| echo: false
# set working directory
# print(getwd())
# setwd("C:/PythonCode/TFM_GLS/")
# print(getwd())
```

```{r}
#| echo: false
library(ggplot2)
library(dplyr)

# FASTTEXT
# INFLECTION
spa_ft_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_fasttext_inflection_results.csv")
pol_ft_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_fasttext_inflection_results.csv")
# DERIVATION
spa_ft_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_fasttext_derivation_results.csv")
pol_ft_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_fasttext_derivation_results.csv")

# WORD2VEC
# INFLECTION
spa_w2v_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_word2vec_inflection_results.csv")
pol_w2v_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_word2vec_inflection_results.csv")
# DERIVATION
spa_w2v_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_word2vec_derivation_results.csv")
pol_w2v_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_word2vec_derivation_results.csv")

# BERT
# INFLECTION
spa_bert_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_bert_inflection_results.csv")
pol_bert_inf <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_bert_inflection_results.csv")
# DERIVATION
spa_bert_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/spa/spa_bert_derivation_results.csv")
pol_bert_der <- read.csv("C:/PythonCode/TFM_GLS/py/results/pol/pol_bert_derivation_results.csv")

# adding model, language and type (inf or der) to the dataset in order to plot it
spa_ft_inf <- spa_ft_inf %>%
  mutate(model = "FastText", language = "Spanish", type = "Inflection")

pol_ft_inf <- pol_ft_inf %>%
  mutate(model = "FastText", language = "Polish", type = "Inflection")

spa_ft_der <- spa_ft_der %>%
  mutate(model = "FastText", language = "Spanish", type = "Derivation")

pol_ft_der <- pol_ft_der %>%
  mutate(model = "FastText", language = "Polish", type = "Derivation")

spa_w2v_inf <- spa_w2v_inf %>%
  mutate(model = "Word2Vec", language = "Spanish", type = "Inflection")

pol_w2v_inf <- pol_w2v_inf %>%
  mutate(model = "Word2Vec", language = "Polish", type = "Inflection")

spa_w2v_der <- spa_w2v_der %>%
  mutate(model = "Word2Vec", language = "Spanish", type = "Derivation")

pol_w2v_der <- pol_w2v_der %>%
  mutate(model = "Word2Vec", language = "Polish", type = "Derivation")

spa_bert_inf <- spa_bert_inf %>%
  mutate(model = "Multilingual BERT", language = "Spanish", type = "Inflection")

pol_bert_inf <- pol_bert_inf %>%
  mutate(model = "Multilingual BERT", language = "Polish", type = "Inflection")

spa_bert_der <- spa_bert_der %>%
  mutate(model = "Multilingual BERT", language = "Spanish", type = "Derivation")

pol_bert_der <- pol_bert_der %>%
  mutate(model = "Multilingual BERT", language = "Polish", type = "Derivation")

```

```{r}
#| echo: false

# spa_ft_inf %>% filter(!grepl("ás", inflection) & grepl("PRS;2;SG", category), 0, ifelse(grepl("FORM", category), 0, 1)))
# spa_ft_der %>% filter (category == "ADJ:ADJ")
# sample

# inflection and derivation datasets
all_inflection <- bind_rows(spa_ft_inf, pol_ft_inf, spa_w2v_inf,
 pol_w2v_inf, spa_bert_inf, pol_bert_inf,)

all_inflection_spa <- bind_rows(spa_ft_inf, spa_w2v_inf, spa_bert_inf)

all_derivation <- bind_rows(spa_ft_der, pol_ft_der, spa_w2v_der,
 pol_w2v_der, spa_bert_der, pol_bert_der)

# # add a new column with "same category" or "different cattegory" to the derivations dataset
all_derivation <- all_derivation %>%
  mutate(type = ifelse(
    gsub(":.*", "", category) == gsub(".*:", "", category),
    "Derivation (same category)", "Derivation (different category)"))

# factoring data (type: inflection, derivation same, derivation diff) on both datasets
all_derivation$type <- as.factor(all_derivation$type)
all_inflection$type <- as.factor(all_inflection$type)
all_inflection_spa$category <- as.factor(all_inflection_spa$category)
# join both datasets
all_df <- bind_rows(all_derivation, all_inflection)

# factor model, language and category
all_df$model <- as.factor(all_df$model)
all_df$language <- as.factor(all_df$language)
all_df$category <- as.factor(all_df$category)

# group by category, model and language and get the mean similarity of each, to plot
# i.e.:       category   model    language   type      mean_similarity
#              ADJ:ADJ   FasText  Polish   Inflection   0.6197
all_df_plot <- all_df %>%
  group_by(category, model, language, type) %>%
  summarise(mean_similarity = mean(similarity, na.rm = TRUE), .groups = 'drop')
```

```{r}
#| column: page
#| echo: false
#| fig-format: svg
#| out-width: 90%
#| fig-width: 22
#| fig-height: 14
#| label: fig-initial-plot
#| fig-cap: "Mean similarity between pivot-form in derivation and inflection by model and language"

# plot1 <- ggplot(all_df_plot, aes(x = type, y = mean_similarity, fill = type)) +
#   geom_dotplot(
#     binaxis = "y", stackdir = "center", 
#     dotsize = 3, binwidth = 0.01, 
#     na.rm = TRUE, alpha = 0.8
#   ) +
#   labs(x = "", y = "Mean similarity") +
#   facet_grid(language ~ model) +
#   stat_summary(
#     fun.data = "mean_cl_boot", 
#     color = "black", size = 1, 
#     position = position_dodge(0.85)
#   ) +
#   theme(
#     plot.margin = margin(t = 10, r = 20, b = 10, l = 40),
#     axis.text.x = element_text(angle = 45, hjust = 1, size = 18),
#     axis.text.y = element_text(size = 16),
#     strip.text = element_text(size = 18)
#   ) +
#   scale_fill_brewer(palette = "Dark2") +
#   guides(fill = "none")
# plot1

# ggsave("C:/PythonCode/TFM_GLS/py/fig-initial-plot.svg", plot = plot1, width = 22, height = 14, units = "in")
```

![Mean similarity between pivot-form in derivation and inflection by model and language](C:/PythonCode/TFM_GLS/py/fig-initial-plot.svg){#fig-initial-plot}


We can see in @fig-initial-plot some weird outliers in FastText and Word2Vec. These outliers correspond to different instances of U:U, X:U or U:X (X being any label). This unknown category is messing with the means so the data needs to be cleaned a bit.

## Cleaning the datasets

The first analysis revealed some errors in both datasets. In the derivations dataset the label U (that *possibly* means unspecified or unknown) presented some issues. The goal is to eliminate all instances of unknown categories, to get rid of this noise and have cleaner results and means.

* In Spanish there are 20 rows that contain a derivation that results in U (i.e. N:U or V:U) and 107 in Polish. 
* On the other hand, there are even more derivations which pivot is tagged with U (U:N, U:ADJ...), 36 in Spanish and 253 in Polish. 

When it comes to Spanish, the number is not too high, so it is something that is worth fixing in order to get rid of this label so it does not mess with the means shown in @fig-initial-plot. Fixing the first group seems fairly easy since we can just look at the affix and the label it is assigned in other rows. The second group cannot be easily fixed with Python so it would probably need to be fixed manually.

```{python}
#| echo: false
#| output: false

import pandas as pd

df = pd.read_csv("C:/PythonCode/TFM_GLS/py/datasets/spa/spa.derivations", sep="\t", header=None, names=["pivot", "derivation", "category", "affix"])

df[df["category"].str.endswith(":U")]
```

In order to clean the Spanish derivations dataset we assign a new category according to the affix. We change all the affixes that end in *-ero*, *-ez*, *-ismo*,*-í* and *-illa* to :N. We also assign :V to those that contain the affixes *-ar* and *-ear*

```{python}

affixes = ["-ero", "-ez", "-ismo", "-í", "-illa"]
condition = df['category'].str.endswith(':U') & df['affix'].isin(affixes)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':N', regex=False)

verb_endings = ["-ear", "-ar"]
condition = df['category'].str.endswith(':U') & df['affix'].isin(verb_endings)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':V', regex=False)

df[df["category"].str.endswith(":U")]
```

As a result we obtain 6 rows that can be eliminated from the final dataset because of all the mistakes they contain.

For the Polish data we do a very similar thing. Affixes such as *-any*, *-ony*, *-ty*, *-y*, or *-ący*, *-ęty* take the label ADJ, because they are all endings that participles take. Some of these affixes are wrong, for example *-ty* and *-y*, UniMorph cannot decide if the suffix takes the 't' or not, but we will ignore this for now.

```{python}
#| echo: false
df = pd.read_csv("C:/PythonCode/TFM_GLS/py/datasets/pol/pol.derivations", sep="\t", header=None, names=["pivot", "derivation", "category", "affix"])
```

```{python}

affixes = ["-any", "-ony", "-ty", "-y", "-ący", "-ęty"]
condition = df['category'].str.endswith(':U') & df['affix'].isin(affixes)
df.loc[condition, 'category'] = df.loc[condition, 'category'].str.replace(':U', ':ADJ', regex=False)
```

We can also see some formatting issues. Some rows contain the pivot and the derived form joined together in the pivot cell (i.e. mylićpomylić	pomylić). This can be fixed as well just removing the form from the pivot cell and assigning to them the correct categories. Some errors can be removed as well, like the appearance of *co*, *kto*, *jaki*.. which are relative pronouns. Everything ending in -ś and -ż or -że are not nouns or adjectives or adverbs or verbs so they can be removed.